{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yifanzhang/miniconda3/envs/legal/lib/python3.11/site-packages/outdated/utils.py:14: OutdatedPackageWarning: The package pingouin is out of date. Your version is 0.5.3, the latest is 0.5.4.\n",
      "Set the environment variable OUTDATED_IGNORE=1 to disable these warnings.\n",
      "  return warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from src.load_data import loader\n",
    "import pingouin as pg\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['StartDate', 'EndDate', 'Status', 'Progress', 'Duration', 'Finished', 'RecordedDate', 'ResponseId', 'DistributionChannel', 'UserLanguage', 'Q_RecaptchaScore', 'Q1', 'Q2', 'Q3_1', 'Q1_2', 'Q1_3', 'Q42', 'Q1.2', 'Q1.3', 'Q1.4', 'Q2.1', 'Q2.2', 'Q2.3', 'Q3.2_1', 'Q3.2_2', 'Q3.2_3', 'Q3.3_1', 'Q3.3_2', 'Q3.3_3', 'Q3.4_1', 'Q3.4_2', 'Q3.4_3', 'Q3.5_1', 'Q3.5_2', 'Q3.5_3', 'Q3.5_4', 'Q3.6_1', 'Q3.6_2', 'Q3.6_3', 'Q3.6_4', 'Q3.7_1', 'Q3.7_2', 'Q3.7_3', 'Q3.8_1', 'Q3.8_2', 'Q3.8_3', 'Q3.9', 'Q3.10_1', 'Q3.10_2', 'Q3.10_3', 'Q3.10_4', 'Q3.10_5', 'Q3.12', 'Q3.12_4_TEXT', 'Q3.13', 'prior legal experien', 'Q3.14', 'Q3.15', 'Q3.15_2_TEXT', 'Q3.16', 'Q3.16_2_TEXT', 'Q3.17', 'Q3.18', 'Admin1_1', 'Admin1_2', 'Admin1_3', 'Admin1_36', 'Admin1_37', 'Admin1_38', 'chatbotRightTrack', 'doneManually', 'experimentId', 'group', 'Start Time', 'End Time']\n"
     ]
    }
   ],
   "source": [
    "data_all = pd.read_table('data/All.tsv', header=0, delimiter='\\t', encoding='utf-16', encoding_errors='replace', keep_default_na=False)\n",
    "print(list(data_all.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group A = EmpathyBot, Anger\n",
    "# Group B = EmpathyBot, NoAnger\n",
    "# Group C = NoEmpathyBot, Anger\n",
    "# Groud D = NoEmpathyBot, NoAnger\n",
    "# Group E = FAQ, Anger\n",
    "# Group F = FAQ, NoAnger\n",
    "\n",
    "# Original Coding from Firebase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groups\n",
    "\n",
    "data_all['EmpathyBot'] = data_all['group'].copy().map({'A':'Empathy', 'B':'Empathy', 'C': 'NoEmpathy', 'D': 'NoEmpathy', 'E': 'FAQ', 'F': 'FAQ'})\n",
    "data_all['AngerInducement'] = data_all['group'].copy().map({'A':'NoAnger', 'C':'NoAnger', 'E':'NoAnger', 'B':'Anger', 'D':'Anger', 'F':'Anger'})\n",
    "group = data_all[['group', 'EmpathyBot', 'AngerInducement']]\n",
    "group.to_csv(\"data/group.csv\",header='group',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demographics\n",
    "\n",
    "demographics_keys = ['Q1','Q2','Q3_1','Q1_3','Q42','group']\n",
    "demo_key_values = ['adult', 'student', 'zipcode', 'age','prior_experience','group']\n",
    "data = data_all[demographics_keys]\n",
    "data.to_csv('data/demographics.csv', header = demo_key_values, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "detailed_demographics_keys = ['Q3.12','Q3.12_4_TEXT','Q3.13','prior legal experien','Q3.14','Q3.15','Q3.15_2_TEXT','Q3.16','Q3.16_2_TEXT','Q3.17','Q3.18']\n",
    "detailed_demo_key_values = ['Gender','Gender_Text','Degree','Law_Ex','Race','P_Language','P_Lan_Text','S_Language','S_Lan_Text','Work','Income']\n",
    "data = data_all[detailed_demographics_keys]\n",
    "data.to_csv('data/detailed_demographics.csv', header = detailed_demo_key_values, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehension Questions\n",
    "comprehension_q_keys = ['Q1.2','Q1.3','Q1.4','Q2.1','Q2.2','Q2.3']\n",
    "data = data_all[comprehension_q_keys]\n",
    "data.to_csv('data/comprehensions.csv',header=comprehension_q_keys, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "comprehensions = pd.read_csv(\"data/comprehensions.csv\")\n",
    "\n",
    "comprehensions['Q1_2'] = comprehensions['Q1.2'].map(lambda x: x == 'May be able to deduct past-due rent from your security deposit')\n",
    "comprehensions['Q1_3'] = comprehensions['Q1.3'].map(lambda x: x == '45 days')\n",
    "comprehensions['Q1_4'] = comprehensions['Q1.4'].map(lambda x: x == '30 days')\n",
    "comprehensions['Q2_1'] = comprehensions['Q2.1'].map(lambda x: x == '$2000')\n",
    "comprehensions['Q2_2'] = comprehensions['Q2.2'].map(lambda x: x == 'Send a letter to the landlord demanding the return of the security deposit')\n",
    "comprehensions['Q2_3'] = comprehensions['Q2.3'].map(lambda x: x == 'The landlord failed to send receipts or an estimate to the tenant within the required time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "comprehensions['Q1_2'] = comprehensions['Q1_2'].replace({True: 1, False: 0})\n",
    "comprehensions['Q1_3'] = comprehensions['Q1_3'].replace({True: 1, False: 0})\n",
    "comprehensions['Q1_4'] = comprehensions['Q1_4'].replace({True: 1, False: 0})\n",
    "comprehensions['Q2_1'] = comprehensions['Q2_1'].replace({True: 1, False: 0})\n",
    "comprehensions['Q2_2'] = comprehensions['Q2_2'].replace({True: 1, False: 0})\n",
    "comprehensions['Q2_3'] = comprehensions['Q2_3'].replace({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = comprehensions[['Q1_2', 'Q1_3', 'Q1_4', 'Q2_1', 'Q2_2', 'Q2_3']].to_numpy()\n",
    "counts = np.count_nonzero(comp, axis=1)\n",
    "comprehensions['ComprehensionCount'] = counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "comprehensions.to_csv('data/comprehensions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Q3.2_1  Q3.2_2  Q3.2_3\n",
      "group                        \n",
      "A        6.53    6.53    6.34\n",
      "B        6.40    6.45    6.30\n",
      "C        6.13    6.20    5.93\n",
      "D        5.96    6.11    6.20\n",
      "E        6.11    6.09    6.17\n",
      "F        6.00    6.07    6.28\n",
      "       Q3.2_1  Q3.2_2  Q3.2_3\n",
      "group                        \n",
      "A        0.75    0.80    0.98\n",
      "B        1.01    0.95    0.98\n",
      "C        1.34    1.38    1.45\n",
      "D        1.45    1.30    1.25\n",
      "E        1.10    1.15    1.08\n",
      "F        0.94    1.08    0.93\n",
      "       Q3.5_1  Q3.5_2  Q3.5_3  Q3.5_4\n",
      "group                                \n",
      "A        6.17    6.11    5.51    6.00\n",
      "B        5.47    5.23    4.55    5.30\n",
      "C        5.70    5.63    4.35    5.33\n",
      "D        5.67    5.78    4.40    5.36\n",
      "E        6.00    5.57    4.57    5.78\n",
      "F        6.20    5.50    5.04    5.85\n",
      "       Q3.5_1  Q3.5_2  Q3.5_3  Q3.5_4\n",
      "group                                \n",
      "A        1.15    1.32    1.68    1.23\n",
      "B        1.65    1.90    1.87    1.65\n",
      "C        1.23    1.25    1.86    1.27\n",
      "D        1.15    1.41    1.91    1.60\n",
      "E        1.35    1.83    1.70    1.49\n",
      "F        1.09    1.85    1.80    1.40\n",
      "       Q3.6_1  Q3.6_2  Q3.6_3  Q3.6_4\n",
      "group                                \n",
      "A        2.51    2.87    2.45    2.64\n",
      "B        2.34    3.15    1.96    2.09\n",
      "C        2.54    2.91    2.26    2.46\n",
      "D        2.67    3.02    2.53    2.27\n",
      "E        3.52    3.76    3.20    3.17\n",
      "F        3.48    4.00    3.20    3.52\n",
      "       Q3.6_1  Q3.6_2  Q3.6_3  Q3.6_4\n",
      "group                                \n",
      "A        1.44    1.44    1.43    1.61\n",
      "B        1.32    1.68    1.28    1.36\n",
      "C        1.63    1.84    1.44    1.44\n",
      "D        1.54    1.78    1.36    1.14\n",
      "E        1.64    1.69    1.59    1.52\n",
      "F        1.92    1.71    1.68    1.76\n"
     ]
    }
   ],
   "source": [
    "# Dependent Variables\n",
    "\n",
    "# ## Helpfulness\n",
    "keys = ['Q3.2_1','Q3.2_2','Q3.2_3']\n",
    "values = ['helpfulness','usefulness','informative']\n",
    "data = data_all[keys]\n",
    "data.to_csv(\"data/dependent_variables/helpfulness.csv\",header=values,index=False)\n",
    "\n",
    "means = data_all.groupby(['group'])[keys].mean().round(2)\n",
    "stds = data_all.groupby(['group'])[keys].std().round(2)\n",
    "print(means)\n",
    "print(stds)\n",
    "\n",
    "# ## Psychological Safety\n",
    "# keys = ['Q3.4_1','Q3.4_2','Q3.4_3']\n",
    "# values = ['CannotTrust','FearCantSatisfy','FrustratedDissatisfied']\n",
    "mapping = {'Agree':7, 'Strongly Agree':6, 'Somewhat Agree':5, 'Neutral':4, 'Somewhat Disagree':3, 'Strongly Disagree':2, 'Disagree':1}\n",
    "# data = data_all[keys]\n",
    "# ndata = data.applymap(lambda x: mapping.get(x))\n",
    "# ndata.to_csv(\"data/dependent_variables/psychological_safety.csv\",header=values,index=False)\n",
    "\n",
    "## Credibility\n",
    "keys = ['Q3.5_1','Q3.5_2','Q3.5_3','Q3.5_4']\n",
    "values = ['Trustworthy','Honesty','Ability','OverallTrust']\n",
    "# print(data_all[keys].head)\n",
    "data_all.replace(mapping, inplace=True)\n",
    "data = data_all[keys]\n",
    "# Mapping is the same\n",
    "data.to_csv(\"data/dependent_variables/credibility.csv\",header=values,index=False)\n",
    "\n",
    "# print(data_all[keys].head)\n",
    "# print(data_all.head)\n",
    "# print(data_all.columns)\n",
    "\n",
    "means = data_all.groupby(['group'])[keys].mean().round(2)\n",
    "stds = data_all.groupby(['group'])[keys].std().round(2)\n",
    "print(means)\n",
    "print(stds)\n",
    "\n",
    "## Cognitive Effort\n",
    "keys = ['Q3.6_1','Q3.6_2','Q3.6_3','Q3.6_4']\n",
    "values = ['Thinking','Contemplated','Demanding','Effort']\n",
    "data = data_all[keys]\n",
    "# Mapping is the same\n",
    "data.to_csv(\"data/dependent_variables/cognitive_effort.csv\",header=values,index=False)\n",
    "\n",
    "means = data_all.groupby(['group'])[keys].mean().round(2)\n",
    "stds = data_all.groupby(['group'])[keys].std().round(2)\n",
    "print(means)\n",
    "print(stds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moderating Varaibles\n",
    "\n",
    "## Anger\n",
    "keys = ['Q3.3_1','Q3.3_2','Q3.3_3']\n",
    "values = ['Mad','Angry','Furious']\n",
    "data = data_all[keys]\n",
    "# Mapping is the same\n",
    "ndata = data.applymap(lambda x: mapping.get(x))\n",
    "ndata.to_csv(\"data/moderating_variables/anger.csv\",header=values,index=False)\n",
    "\n",
    "## Online Preference\n",
    "keys = ['Q3.8_1','Q3.8_2','Q3.8_3']\n",
    "values = ['Perfer','Comfort','online']\n",
    "data = data_all[keys]\n",
    "# Mapping is the same\n",
    "ndata = data.applymap(lambda x: mapping.get(x))\n",
    "ndata.to_csv(\"data/moderating_variables/online_preference.csv\",header=values,index=False)\n",
    "\n",
    "# Need for Empathy\n",
    "# keys = ['Q3.10_1','Q3.10_2','Q3.10_3','Q3.10_4','Q3.10_5']\n",
    "# values = ['Compassionate','Realize','Misfortune','TenderFeelings','Friend']\n",
    "## Removed Realize\n",
    "keys = ['Q3.10_1','Q3.10_3','Q3.10_4','Q3.10_5']\n",
    "values = ['Compassionate','Misfortune','TenderFeelings','Friend']\n",
    "## Removed Friend\n",
    "# keys = ['Q3.10_1','Q3.10_2','Q3.10_3','Q3.10_4']\n",
    "# values = ['Compassionate','Realize','Misfortune','TenderFeelings']\n",
    "data = data_all[keys]\n",
    "# Mapping is the same\n",
    "ndata = data.applymap(lambda x: mapping.get(x))\n",
    "ndata.to_csv(\"data/moderating_variables/empathy.csv\",header=values,index=False)\n",
    "\n",
    "## Chatbot Familiarity\n",
    "key = ['Q3.9']\n",
    "value = ['Familiarity']\n",
    "data = data_all[key]\n",
    "mapping = {'No':0, 'Yes':1}\n",
    "ndata = data.applymap(lambda x: mapping.get(x))\n",
    "ndata.to_csv(\"data/moderating_variables/chatbot_familiarity.csv\",header=value,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mean and standard deviation of each dependent variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'credibility': (0.8314952217091008, array([0.797, 0.862])), 'cognitive_effort': (0.8678723211232615, array([0.841, 0.892])), 'helpfulness': (0.9299553662000406, array([0.914, 0.943]))}\n",
      "{'anger': (nan, array([nan, nan])), 'online_preference': (nan, array([nan, nan])), 'empathy': (nan, array([nan, nan]))}\n"
     ]
    }
   ],
   "source": [
    "# Cronbach's alpha\n",
    "\n",
    "# dependent_variables\n",
    "l = loader()\n",
    "dependent_variables, moderating_variables = l.load_data()\n",
    "\n",
    "dependent_variables_alphas = {}\n",
    "for data_name in dependent_variables.keys():\n",
    "    dependent_variables_alphas[data_name] = pg.cronbach_alpha(data=dependent_variables.get(data_name))\n",
    "print(dependent_variables_alphas)\n",
    "\n",
    "# Moderating Variables\n",
    "moderating_variables_alphas = {}\n",
    "for data_name in moderating_variables.keys():\n",
    "    if data_name != 'chatbot_familiarity':\n",
    "    # chatbot_familiarity cannot do cronbach's alpha because it only have one item\n",
    "        moderating_variables_alphas[data_name] = pg.cronbach_alpha(data=moderating_variables[data_name])\n",
    "print(moderating_variables_alphas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
