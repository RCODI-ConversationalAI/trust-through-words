{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from statsmodels.stats.power import FTestAnovaPower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Effort', 'Helpfulness', 'Trustworthy', 'Anger', 'Online', 'Empathy',\n",
       "       'Familiarity', 'group', 'EmpathyBot', 'AngerInducement', 'WithAnger',\n",
       "       'Q1.2', 'Q1.3', 'Q1.4', 'Q2.1', 'Q2.2', 'Q2.3', 'Q1_2', 'Q1_3', 'Q1_4',\n",
       "       'Q2_1', 'Q2_2', 'Q2_3', 'ComprehensionCount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/all_weights.csv')\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['systemizing'] = data['EmpathyBot'].map({\n",
    "    'NonEmpathy': 1,\n",
    "    'FAQ': -1,\n",
    "    'Empathy': 0\n",
    "})\n",
    "data['empathizing'] = data['EmpathyBot'].map({\n",
    "    'Empathy': 1,\n",
    "    'NonEmpathy': -1,\n",
    "    'FAQ': 0\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mean_var_total(data, dependent_var, condition):\n",
    "    mean = data[dependent_var][data[condition].isin([1, -1])].mean()\n",
    "    var = data[dependent_var][data[condition].isin([1, -1])].var()\n",
    "    print(f\"{dependent_var} - {condition} Mean: {mean:.2f}, Variance: {var:.2f}\")\n",
    "    return mean, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effort - systemizing Mean: 9.49, Variance: 19.98\n",
      "Effort - empathizing Mean: 7.92, Variance: 15.35\n",
      "Helpfulness - systemizing Mean: 15.70, Variance: 8.74\n",
      "Helpfulness - empathizing Mean: 16.12, Variance: 7.92\n",
      "Trustworthy - systemizing Mean: 16.09, Variance: 13.18\n",
      "Trustworthy - empathizing Mean: 16.03, Variance: 14.34\n"
     ]
    }
   ],
   "source": [
    "for dependent_var in ['Effort', 'Helpfulness', 'Trustworthy']:\n",
    "    for condition in ['systemizing', 'empathizing']:\n",
    "        find_mean_var_total(data, dependent_var, condition)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find mean and variance\n",
    "def find_mean_var(data, dependent_var, condition):\n",
    "    positive_mean = data[dependent_var][data[condition] == 1].mean()\n",
    "    positive_var = data[dependent_var][data[condition] == 1].var()\n",
    "    negative_mean = data[dependent_var][data[condition] == -1].mean()\n",
    "    negative_var = data[dependent_var][data[condition] == -1].var()\n",
    "    print(f\"{dependent_var} - {condition} Positive Mean: {positive_mean:.2f}, Positive Variance: {positive_var:.2f}, Negative Mean: {negative_mean:.2f}, Negative Variance: {negative_var:.2f}\")\n",
    "    return positive_mean, positive_var, negative_mean, negative_var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effort - systemizing Positive Mean: 8.07, Positive Variance: 16.36, Negative Mean: 10.90, Negative Variance: 19.75\n",
      "Effort - empathizing Positive Mean: 7.78, Positive Variance: 14.50, Negative Mean: 8.07, Negative Variance: 16.36\n",
      "Helpfulness - systemizing Positive Mean: 15.67, Positive Variance: 11.13, Negative Mean: 15.74, Negative Variance: 6.48\n",
      "Helpfulness - empathizing Positive Mean: 16.56, Positive Variance: 4.51, Negative Mean: 15.67, Negative Variance: 11.13\n",
      "Trustworthy - systemizing Positive Mean: 15.63, Positive Variance: 12.74, Negative Mean: 16.53, Negative Variance: 13.35\n",
      "Trustworthy - empathizing Positive Mean: 16.40, Positive Variance: 15.75, Negative Mean: 15.63, Negative Variance: 12.74\n"
     ]
    }
   ],
   "source": [
    "for dependent_var in ['Effort', 'Helpfulness', 'Trustworthy']:\n",
    "    for condition in ['systemizing', 'empathizing']:\n",
    "        find_mean_var(data, dependent_var, condition)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NonEmpathy', 'FAQ', 'Empathy'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['EmpathyBot'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find mean and variance when condition is EmpathyBot\n",
    "def find_mean_var_empathybot(data, dependent_var):\n",
    "    level1_mean = data[dependent_var][data['EmpathyBot'] == 'NonEmpathy'].mean()\n",
    "    level1_var = data[dependent_var][data['EmpathyBot'] == 'NonEmpathy'].var()\n",
    "    level2_mean = data[dependent_var][data['EmpathyBot'] == 'FAQ'].mean()\n",
    "    level2_var = data[dependent_var][data['EmpathyBot'] == 'FAQ'].var()\n",
    "    level3_mean = data[dependent_var][data['EmpathyBot'] == 'Empathy'].mean()\n",
    "    level3_var = data[dependent_var][data['EmpathyBot'] == 'Empathy'].var()\n",
    "    print(f\"{dependent_var} - EmpathyBot Level 1 Mean: {level1_mean:.2f}, Level 1 Variance: {level1_var:.2f}\")\n",
    "    print(f\"Level 2 Mean: {level2_mean:.2f}, Level 2 Variance: {level2_var:.2f}\")\n",
    "    print(f\"Level 3 Mean: {level3_mean:.2f}, Level 3 Variance: {level3_var:.2f}\")\n",
    "    return level1_mean, level1_var, level2_mean, level2_var, level3_mean, level3_var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effort - EmpathyBot Level 1 Mean: 8.07, Level 1 Variance: 16.36\n",
      "Level 2 Mean: 10.90, Level 2 Variance: 19.75\n",
      "Level 3 Mean: 7.78, Level 3 Variance: 14.50\n",
      "Helpfulness - EmpathyBot Level 1 Mean: 15.67, Level 1 Variance: 11.13\n",
      "Level 2 Mean: 15.74, Level 2 Variance: 6.48\n",
      "Level 3 Mean: 16.56, Level 3 Variance: 4.51\n",
      "Trustworthy - EmpathyBot Level 1 Mean: 15.63, Level 1 Variance: 12.74\n",
      "Level 2 Mean: 16.53, Level 2 Variance: 13.35\n",
      "Level 3 Mean: 16.40, Level 3 Variance: 15.75\n"
     ]
    }
   ],
   "source": [
    "for dependent_var in ['Effort', 'Helpfulness', 'Trustworthy']:\n",
    "    find_mean_var_empathybot(data, dependent_var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mean_var_empathybot_total(data, dependent_var):\n",
    "    mean = data[dependent_var].mean()\n",
    "    var = data[dependent_var].var()\n",
    "    print(f\"{dependent_var} - EmpathyBot Mean: {mean:.2f}, Variance: {var:.2f}\")\n",
    "    return mean, var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effort - EmpathyBot Mean: 8.91, Variance: 18.72\n",
      "Helpfulness - EmpathyBot Mean: 15.99, Variance: 7.45\n",
      "Trustworthy - EmpathyBot Mean: 16.19, Variance: 14.02\n"
     ]
    }
   ],
   "source": [
    "for dependent_var in ['Effort', 'Helpfulness', 'Trustworthy']:\n",
    "    find_mean_var_empathybot_total(data, dependent_var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to test type 1 error\n",
    "def test_type_1_error(data, dependent_var, condition, alpha=0.05, n_simulations=1000):\n",
    "    # Get the null distribution (when H0 is true - no difference between groups)\n",
    "    null_data = data[data[condition].isin([1, -1])][dependent_var].to_numpy()\n",
    "    type_1_errors = 0\n",
    "    \n",
    "    for _ in range(n_simulations):\n",
    "        # Randomly split the data into two groups\n",
    "        shuffled_data = null_data.copy()\n",
    "        np.random.shuffle(shuffled_data)\n",
    "        group1 = shuffled_data[:len(shuffled_data)//2]\n",
    "        group2 = shuffled_data[len(shuffled_data)//2:]\n",
    "        \n",
    "        # Perform t-test\n",
    "        t_stat, p_value = ttest_ind(group1, group2, equal_var=False)\n",
    "        \n",
    "        # Count type 1 errors (rejecting H0 when it's true)\n",
    "        if p_value < alpha:\n",
    "            type_1_errors += 1\n",
    "    \n",
    "    type_1_error_rate = type_1_errors / n_simulations\n",
    "    print(f\"{dependent_var} - {condition} Type 1 Error Rate: {type_1_error_rate:.3f}\")\n",
    "    return type_1_error_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to test type 2 error\n",
    "def test_type_2_error_bootstrap(data, dependent_var, condition, alpha=0.05, n_simulations=1000):\n",
    "    \"\"\"Bootstrap approach - resamples from actual data distribution\"\"\"\n",
    "    # Get original groups\n",
    "    group1_data = data[data[condition] == -1][dependent_var].to_numpy()\n",
    "    group2_data = data[data[condition] == 1][dependent_var].to_numpy()\n",
    "    \n",
    "    # Calculate original effect size\n",
    "    pooled_std = np.sqrt((group1_data.var() + group2_data.var()) / 2)\n",
    "    observed_effect_size = abs(group1_data.mean() - group2_data.mean()) / pooled_std\n",
    "    \n",
    "    type_2_errors = 0\n",
    "    for _ in range(n_simulations):\n",
    "        # Resample with replacement from original data\n",
    "        bootstrap_group1 = np.random.choice(group1_data, size=len(group1_data), replace=True)\n",
    "        bootstrap_group2 = np.random.choice(group2_data, size=len(group2_data), replace=True)\n",
    "        \n",
    "        # Perform t-test\n",
    "        t_stat, p_value = ttest_ind(bootstrap_group1, bootstrap_group2, equal_var=False)\n",
    "        \n",
    "        if p_value >= alpha:\n",
    "            type_2_errors += 1\n",
    "    \n",
    "    type_2_error_rate = type_2_errors / n_simulations\n",
    "    print(f\"{dependent_var} - {condition} Estimated Type 2 Error Rate (Bootstrap): {type_2_error_rate:.3f}\")\n",
    "    return type_2_error_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effort - systemizing Type 1 Error Rate: 0.059\n",
      "Effort - systemizing Estimated Type 2 Error Rate (Bootstrap): 0.008\n",
      "Effort - empathizing Type 1 Error Rate: 0.034\n",
      "Effort - empathizing Estimated Type 2 Error Rate (Bootstrap): 0.915\n",
      "Helpfulness - systemizing Type 1 Error Rate: 0.047\n",
      "Helpfulness - systemizing Estimated Type 2 Error Rate (Bootstrap): 0.953\n",
      "Helpfulness - empathizing Type 1 Error Rate: 0.051\n",
      "Helpfulness - empathizing Estimated Type 2 Error Rate (Bootstrap): 0.406\n",
      "Trustworthy - systemizing Type 1 Error Rate: 0.054\n",
      "Trustworthy - systemizing Estimated Type 2 Error Rate (Bootstrap): 0.584\n",
      "Trustworthy - empathizing Type 1 Error Rate: 0.049\n",
      "Trustworthy - empathizing Estimated Type 2 Error Rate (Bootstrap): 0.708\n"
     ]
    }
   ],
   "source": [
    "for dependent_var in ['Effort', 'Helpfulness', 'Trustworthy']:\n",
    "    for condition in ['systemizing', 'empathizing']:\n",
    "        test_type_1_error(data, dependent_var, condition)\n",
    "        test_type_2_error_bootstrap(data, dependent_var, condition)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_type_1_error_total(data, dependent_var, n_simulations=1000, alpha=0.05):\n",
    "    null_data = data[dependent_var].to_numpy()\n",
    "    type_1_errors = 0\n",
    "\n",
    "    for _ in range(n_simulations):\n",
    "        shuffled_data = null_data.copy()\n",
    "        np.random.shuffle(shuffled_data)\n",
    "        group1 = shuffled_data[:len(shuffled_data)//2]\n",
    "        group2 = shuffled_data[len(shuffled_data)//2:]\n",
    "    \n",
    "        t_stat, p_value = ttest_ind(group1, group2, equal_var=False)\n",
    "\n",
    "        if p_value < alpha:\n",
    "            type_1_errors += 1\n",
    "    \n",
    "    type_1_error_rate = type_1_errors / n_simulations\n",
    "    print(f\"{dependent_var} - Total Type 1 Error Rate: {type_1_error_rate:.3f}\")\n",
    "    return type_1_error_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_type_2_error_main_effect(data, dependent_var, factor='EmpathyBot', alpha=0.05, n_simulations=1000):\n",
    "    \"\"\"\n",
    "    Calculate Type 2 error rate for main effect of a factor with 3 levels\n",
    "    factor: Factor with 3 levels (e.g., 'NonEmpathy', 'FAQ', 'Empathy')\n",
    "    \"\"\"\n",
    "    # Get original groups\n",
    "    groups = [group[dependent_var].to_numpy() for name, group in data.groupby(factor)]\n",
    "    \n",
    "    # Calculate original F-statistic\n",
    "    f_stat, p_val = stats.f_oneway(*groups)\n",
    "    \n",
    "    type_2_errors = 0\n",
    "    \n",
    "    for _ in range(n_simulations):\n",
    "        # Bootstrap sample with replacement\n",
    "        bootstrap_groups = []\n",
    "        for group in groups:\n",
    "            bootstrap_group = np.random.choice(group, size=len(group), replace=True)\n",
    "            bootstrap_groups.append(bootstrap_group)\n",
    "        \n",
    "        # Perform one-way ANOVA\n",
    "        _, p_value = stats.f_oneway(*bootstrap_groups)\n",
    "        \n",
    "        # Count Type 2 errors (failing to reject H0 when there is an effect)\n",
    "        if p_value >= alpha:\n",
    "            type_2_errors += 1\n",
    "    \n",
    "    type_2_error_rate = type_2_errors / n_simulations\n",
    "    power = 1 - type_2_error_rate\n",
    "    \n",
    "    print(f\"\\n{dependent_var} - {factor} Main Effect:\")\n",
    "    print(f\"Type 2 Error Rate: {type_2_error_rate:.3f}\")\n",
    "    print(f\"Statistical Power: {power:.3f}\")\n",
    "    \n",
    "    return type_2_error_rate, power\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effort - Total Type 1 Error Rate: 0.049\n",
      "\n",
      "Effort - EmpathyBot Main Effect:\n",
      "Type 2 Error Rate: 0.000\n",
      "Statistical Power: 1.000\n",
      "Helpfulness - Total Type 1 Error Rate: 0.053\n",
      "\n",
      "Helpfulness - EmpathyBot Main Effect:\n",
      "Type 2 Error Rate: 0.368\n",
      "Statistical Power: 0.632\n",
      "Trustworthy - Total Type 1 Error Rate: 0.041\n",
      "\n",
      "Trustworthy - EmpathyBot Main Effect:\n",
      "Type 2 Error Rate: 0.658\n",
      "Statistical Power: 0.342\n"
     ]
    }
   ],
   "source": [
    "for dependent_var in ['Effort', 'Helpfulness', 'Trustworthy']:\n",
    "    test_type_1_error_total(data, dependent_var)\n",
    "    test_type_2_error_main_effect(data, dependent_var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# power analysis\n",
    "def simple_power_analysis(design_type, alpha=0.05, power=0.8):\n",
    "    \"\"\"\n",
    "    Calculate required sample sizes for different effect sizes\n",
    "    design_type: either '2x2' (4 groups) or '3x2' (6 groups)\n",
    "    \"\"\"\n",
    "    # Initialize power analysis\n",
    "    power_analysis = FTestAnovaPower()\n",
    "    \n",
    "    # Set effect sizes (Cohen's f)\n",
    "    effect_sizes = {\n",
    "        'small': 0.10,\n",
    "        'medium': 0.25,\n",
    "        'large': 0.40\n",
    "    }\n",
    "    \n",
    "    # Set number of groups\n",
    "    groups = 4 if design_type == '2x2' else 6\n",
    "    \n",
    "    # Calculate required sample sizes\n",
    "    results = {}\n",
    "    for effect_name, f in effect_sizes.items():\n",
    "        n = power_analysis.solve_power(\n",
    "            effect_size=f,\n",
    "            power=power,\n",
    "            alpha=alpha,\n",
    "            k_groups=groups\n",
    "        )\n",
    "        results[effect_name] = {\n",
    "            'total_n': int(np.ceil(n)),\n",
    "            'n_per_group': int(np.ceil(n/groups))\n",
    "        }\n",
    "    \n",
    "    print(f\"\\nRequired Sample Sizes for {design_type} Design:\")\n",
    "    print(f\"{'Effect Size':<12} {'Total N':<10} {'N per Group':<12}\")\n",
    "    print(\"-\" * 34)\n",
    "    for effect, ns in results.items():\n",
    "        print(f\"{effect:<12} {ns['total_n']:<10} {ns['n_per_group']:<12}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Required Sample Sizes for 2x2 Design:\n",
      "Effect Size  Total N    N per Group \n",
      "----------------------------------\n",
      "small        1095       274         \n",
      "medium       179        45          \n",
      "large        73         19          \n",
      "\n",
      "Required Sample Sizes for 3x2 Design:\n",
      "Effect Size  Total N    N per Group \n",
      "----------------------------------\n",
      "small        1289       215         \n",
      "medium       211        36          \n",
      "large        86         15          \n"
     ]
    }
   ],
   "source": [
    "for design in ['2x2', '3x2']:\n",
    "    simple_power_analysis(design)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "legal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
